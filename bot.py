import os
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, ContextTypes, filters
from openai import OpenAI
from dotenv import load_dotenv

# –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∑–º—ñ–Ω–Ω–∏—Ö —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞
load_dotenv()
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –∫–ª—ñ—î–Ω—Ç–∞ OpenAI
client = OpenAI(api_key=OPENAI_API_KEY)

# –§—É–Ω–∫—Ü—ñ—è –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ
def generate_openai_response(prompt: str) -> str:
    try:
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "–¢–∏ ‚Äî –¥–æ–±—Ä–æ–∑–∏—á–ª–∏–≤–∏–π Telegram-–±–æ—Ç –Ω–∞ –±–∞–∑—ñ ChatGPT."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=500,
            temperature=0.7,
            timeout=10
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        return f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–≤–µ—Ä–Ω–µ–Ω–Ω—ñ –¥–æ OpenAI: {e}"

# –û–±—Ä–æ–±–∫–∞ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å
async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_message = update.message.text
    bot_response = generate_openai_response(user_message)
    await update.message.reply_text(bot_response)

# –ö–æ–º–∞–Ω–¥–∞ /start
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text('üëã –ü—Ä–∏–≤—ñ—Ç! –Ø –±–æ—Ç –Ω–∞ –±–∞–∑—ñ ChatGPT. –ù–∞–ø–∏—à–∏ –º–µ–Ω—ñ —â–æ—Å—å!')

# –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞
def main():
    application = Application.builder().token(TELEGRAM_TOKEN).build()

    application.add_handler(CommandHandler("start", start))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

    print("‚úÖ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω–æ... –û—á—ñ–∫—É—î–º–æ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å")
    application.run_polling()

if __name__ == '__main__':
    main()
